# Lecture 8 script: Network Data and Graph Workflows

## Slide 1 — Title

In this lecture we’re going to talk about network data and graph workflows.

The central idea is that many social processes are fundamentally relational. If you only look at attributes of individual units—states, people, organizations—you miss the structure of interaction: who connects to whom, who depends on whom, how influence flows, how conflict cascades, and how cooperation emerges.

Network methods make relations explicit. But they also force you to make choices that are easy to overlook: what counts as a node, what counts as an edge, how edges are directed or weighted, and what the unit of analysis is.

So today I’ll start with representation—how we build networks from tables—and then I’ll move through descriptive measures, statistical network models, diffusion models, and finally graph neural networks. As always in this course: the goal is to connect tools to measurement and inference, not to memorize software.

**[pause]**

---

## Slide 2 — Why networks matter

Why do networks matter?

Many social processes are relational: conflict and cooperation, information diffusion, influence and dependency, collective action.

If you care about any of those, relationships are not noise. They are the mechanism.

For example: in international relations, the effect of capabilities often depends on alliances, trade ties, and shared institutions. In political communication, influence depends on who is connected to whom and who amplifies what. In organizations, outcomes depend on reporting lines and informal networks.

So the claim on this slide is: networks make relations explicit. They turn “relationships” into an analyzable object.

---

## Slide 3 — What is network data

Network data consist of nodes, edges, and attributes on both.

Nodes can be actors, units, organizations, states, legislators—whatever you define.

Edges are relations: interactions, ties, flows, co-membership, co-sponsorship, communications, conflict events.

Attributes can live on nodes—like ideology, GDP, or party—and on edges—like tie strength, frequency, or type.

And the key line is: the unit of analysis is often the tie, not the node.

That’s a mindset shift. In a typical regression, the unit is an individual or a state-year. In network analysis, the basic observation can be the dyad—the relationship between i and j—and those dyads are not independent.

That dependence is a major reason network-specific models exist.

---

## Slide 4 — From tables to graphs

Network construction requires choices.

What counts as a node? What counts as a tie? Is the network directed or undirected? Are edges weighted or binary?

These are not cosmetic decisions. Representation decisions shape inference.

A quick example: if you define a tie as “any interaction,” your network will be dense. If you define a tie as “at least five interactions,” it might become sparse. If you treat ties as directed, you can study who initiates and who receives. If you treat ties as undirected, you collapse directionality and you lose certain mechanisms.

So a core skill in network research is being explicit about construction rules and checking how sensitive results are to those rules.

---

## Slide 5 — Graph construction (conceptual)

This slide shows the basic idea: we often start with an edge list—rows are ties, with a sender and a receiver—and then we construct a graph object.

The technical details differ across tools, but the logic is constant:

* identify the source column and target column,
* decide whether the graph is directed,
* optionally add weights and attributes.

The deeper point is that graph construction is the “data creation” step for networks. Once you build the graph, everything you compute—centrality, communities, diffusion, models—depends on that constructed object.

So in your pipeline, this step should be documented and auditable: what rows went in, what filters were applied, what definition of a tie was used.

---

## Slide 6 — Centrality measures

Centrality captures different notions of importance: degree, betweenness, eigenvector or PageRank.

The key warning is on the slide: no single measure is universally correct.

Degree is about number of ties—popularity or activity, depending on direction.

Betweenness is about brokerage—being on paths between others.

Eigenvector and PageRank are about being connected to others who are themselves connected—influence by association.

So centrality is not “importance” in the abstract. It’s importance relative to a particular mechanism.

A good habit is to say: what mechanism would make this centrality measure the right one? If you can’t answer that, the centrality result is hard to interpret.

---

## Slide 7 — Community detection

Communities identify clusters of dense ties, functional groupings, or latent structure.

But the key point is: algorithms impose assumptions about structure.

Community detection is not “finding the true communities.” It is partitioning the graph according to an objective function—like modularity—or according to a model assumption.

Different algorithms can yield different partitions. Even the same algorithm can yield different partitions depending on resolution parameters.

So community detection is a descriptive tool and sometimes a modeling step, but it requires interpretation and sensitivity checks. In a data pipeline mindset: communities are outputs that must be validated, not facts that exist independent of method.

---

## Slide 8 — Statistical network models

Now we move from descriptive measures to statistical network models.

Statistical network models treat networks as outcomes. Ties are random variables. Structure is explained, not assumed. Dependence is explicit.

This is where network analysis diverges from “apply a regression to dyads.” Dyadic outcomes are dependent because a node appears in many dyads, and because ties can cluster due to reciprocity, transitivity, popularity, and latent group structure.

Statistical models try to model those dependencies rather than ignore them.

So think of this as the difference between summarizing a network and explaining why it looks the way it does.

---

## Slide 9 — ERGMs (local dependence)

ERGMs, or exponential random graph models, are a framework for modeling local dependence—how small configurations generate global structure.

The pseudocode here expresses the conceptual logic: you define network statistics—edges, reciprocity, triangles, and so on—and then you define a probability distribution over networks that favors networks with certain statistics.

The algorithmic flavor often involves proposing alternative networks and accepting them with probability related to how the statistics change. This is why ERGMs can be computationally challenging: the space of possible networks is huge.

The interpretation lesson is: ERGMs explain why certain local configurations appear. They’re good when your theory is about structural tendencies—reciprocity, clustering, triadic closure, homophily—and you want parameters that correspond to those tendencies.

But they are sensitive to specification, and they can be hard to fit on very large networks. So the question is always: does the model match the theoretical mechanism, and is it feasible given the data?

---

## Slide 10 — AME models (latent structure)

AME models—additive and multiplicative effects—are another major family.

The pseudocode on the slide captures the key idea: you model a dyadic outcome as a function of covariates, plus sender effects, receiver effects, and a low-rank latent term that captures unobserved structure.

The intuition is that latent positions summarize unobserved dependence. Actors can be positioned in a latent space, and ties are more likely when latent positions align in certain ways.

AME models often scale better than ERGMs and align more naturally with regression intuition: you still have covariates and effects, but you also have a structured residual component.

In applied terms: AME is useful when you suspect there is unobserved structure—like blocs, latent affinity, or hidden confounding—that generates dependence across dyads.

---

## Slide 11 — Diffusion models

Diffusion models study how behaviors spread, how events cascade, and how influence propagates.

The pseudocode here is an event-history-style intuition: for each time period and actor, compute exposure based on neighbors’ past events, convert that exposure into a hazard, and then events occur probabilistically.

The key contribution of diffusion models is that they make time and exposure explicit. They ask: given the network, and given what neighbors did previously, does exposure increase the probability of adoption or action?

In social science, this matters because “diffusion” is often a claim about mechanism. But without modeling exposure and time explicitly, diffusion claims can become descriptive: “things spread.” Diffusion models force you to specify what “spread” means.

And importantly: diffusion models are often sensitive to how you define exposure—what counts as a neighbor, what time window matters, whether influence decays, and whether ties are weighted.

So again: representation and measurement choices are central.

---

## Slide 12 — Graph neural networks (GNNs)

GNNs are a different paradigm.

They learn representations from graph structure. They combine node features and topology and enable prediction on networks.

The pseudocode shows the message-passing intuition: initialize node representations, then for multiple layers, aggregate messages from neighbors and update each node’s representation. At the end, use the learned representations for prediction—node classification, link prediction, or graph-level tasks.

The key tradeoff is on the slide: they trade interpretability for flexibility.

This is why it’s useful to connect GNNs to the broader course themes. GNNs can be powerful predictors, but they can also become black boxes. If your goal is explanation—causal or theoretical—GNNs often require additional work to interpret.

So the choice between GNNs and statistical network models is not just about performance. It’s about research goals: prediction versus explanation.

---

## Slide 13 — Model comparison

This slide is a summary that’s worth emphasizing verbally.

ERGMs: explain local structure; interpretable parameters; scale poorly.

AMEs: explain latent dependence; scalable; interpretable geometry.

Diffusion models: explain temporal contagion; often align with causal intuition; require time and careful exposure definitions.

GNNs: optimize prediction; limited interpretability; strong when you have rich data and prediction goals.

This is a decision framework: match model families to what you want to learn.

If your paper’s core claim is “reciprocity drives cooperation,” an ERGM might be natural. If your claim is “unobserved blocs structure conflict ties,” an AME model might be natural. If your claim is “violence spreads through networks,” diffusion models are natural. If your goal is “predict which edges form,” GNNs might be natural.

The important point is: the model choice is a substantive choice.

---

## Slide 14 — Validation in network analysis

Validation is hard in network analysis because observations are dependent.

Common challenges include dependence across observations, overfitting structure, and temporal instability.

Out-of-sample checks are essential.

That can mean:

* predicting held-out edges,
* training on earlier time windows and predicting later ones,
* using null models to assess whether a pattern is more than degree distribution,
* checking sensitivity to network construction.

The key lesson is: network methods can produce compelling pictures even when the signal is weak. Validation is how you separate “interesting visualization” from “reliable inference.”

---

## Slide 15 — What we emphasize in practice

Let me summarize the habits we emphasize.

Start with clear representations. If you can’t define nodes and edges precisely, nothing downstream is stable.

Match models to questions. Don’t pick a method because it’s popular; pick it because it answers a question.

Be explicit about dependence. Network data violate independence assumptions; pretending otherwise is a major error.

Validate aggressively. Check sensitivity to construction, check out-of-sample performance where relevant, and be transparent about uncertainty.

---

## Slide 16 — Discussion

Let me close with three questions.

Which network choices feel most consequential? In your own work, is it the definition of a tie, directionality, weighting, or temporal aggregation?

When do black-box models make sense? Under what conditions is prediction the goal, and what interpretability do you need?

And how should uncertainty be communicated? Network results often look precise—centrality rankings, community labels, diffusion estimates—but much of that depends on construction choices. How do you communicate that dependence clearly?

**[pause]**
